{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from heapq import nsmallest, nlargest\n",
    "from numpy import NaN, linalg as LA\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe414af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDocument:\n",
    " \n",
    "\n",
    "  def __init__(self, doc_ID, tokens, all_docs_count, url):\n",
    "\n",
    "    self.doc_ID = doc_ID\n",
    "    self.tokens = tokens\n",
    "    self.docs_count = all_docs_count\n",
    "    self.url = url\n",
    "\n",
    "    \n",
    "  def calculate_tfidf(self, word, document_frequncy_of_word):\n",
    "    term_frequency = self.tokens.count(word)\n",
    "    tfidf = 0\n",
    "    if term_frequency > 0:\n",
    "      tfidf = (1 + math.log(term_frequency)) * math.log((self.docs_count/document_frequncy_of_word))\n",
    "\n",
    "    # if tfidf <0 :\n",
    "    #   print(\"tfidf \", tfidf)\n",
    "    \n",
    "    # if  tfidf < 0:\n",
    "    #   print(\"negativeeeeeeeeeeeeeee\")\n",
    "    return  tfidf\n",
    "  \n",
    "  def create_vector(self, dictionary):\n",
    "    self.vector_list = []\n",
    "\n",
    "    for key in list(dictionary):\n",
    "      self.vector_list.append(self.calculate_tfidf(key, dictionary[key]))\n",
    "    \n",
    "    self.vector = np.array(self.vector_list)\n",
    "\n",
    "    # print(self.vector)\n",
    "    \n",
    "    # if not np.any(self.vector):\n",
    "    #   return -1\n",
    "    # return 0\n",
    "\n",
    "  def get_doc_ID (self):\n",
    "    return self.doc_ID\n",
    "\n",
    "  def get_vector (self):\n",
    "\n",
    "    return self.vector\n",
    "\n",
    "  def get_url(self):\n",
    "    return self.url\n",
    "\n",
    "  def find_cosine_distance_from_query(self, query_vector):\n",
    "\n",
    "  \n",
    "    # return np.dot(self.vector,query_vector) / (LA.norm(self.vector) * LA.norm(query_vector))\n",
    "\n",
    "    # index elimination\n",
    "    indexes_of_none_zero_terms = np.where(query_vector == 0)[0]\n",
    "    cosine = 0\n",
    "    for index in indexes_of_none_zero_terms:\n",
    "      cosine += query_vector[index] * self.vector[index]\n",
    "    cosine = cosine / (LA.norm(np.nonzero(self.vector)) * LA.norm(np.nonzero(query_vector)))\n",
    "    return cosine\n",
    "\n",
    "  def find_cosine_distances_from_all_news(self, all_news, term_postings):  ############### Why is very slow\n",
    "\n",
    "      # self.news_cosines_distances = {}\n",
    "\n",
    "      # for news in all_news:\n",
    "      #   # print(news)\n",
    "      #   # print(\"SALAMMMMMM\")\n",
    "      #   news_vector = news.get_vector()\n",
    "      #   # print(\"news vector \\n {}\".format(news_vector))\n",
    "      #   self.news_cosines_distances[news] = np.dot(self.vector,news_vector) / (LA.norm(self.vector) * LA.norm(news_vector))\n",
    "     \n",
    "      # with new combination method \n",
    "    \n",
    "      self.news_cosines_distances = {}\n",
    "     \n",
    "      related_news = set()\n",
    "      for term in self.tokens:\n",
    "        if term in list(term_postings):\n",
    "          related_news.update(term_postings[term])\n",
    "\n",
    "\n",
    "      for news in related_news:\n",
    "        # print(news)\n",
    "        # print(\"SALAMMMMMM\")\n",
    "        news_vector = news.get_vector()\n",
    "        # print(\"news vector \\n {}\".format(news_vector))\n",
    "        self.news_cosines_distances[news] = np.dot(self.vector,news_vector) / (LA.norm(self.vector) * LA.norm(news_vector))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      # # with index elimination \n",
    "      # indexes_of_none_zero_terms = np.where(self.vector == 0)[0]\n",
    "      # self.news_cosines_distances = {}\n",
    "     \n",
    "      # related_news = set()\n",
    "      # for term in self.tokens:\n",
    "      #     related_news.update(term_postings[term])\n",
    "\n",
    "\n",
    "      # for news in related_news:\n",
    "      #   cosine = 0\n",
    "      #   # print(\"INNN\")\n",
    "      #   news_vector = news.get_vector()\n",
    "      #   for index in indexes_of_none_zero_terms:\n",
    "      #     cosine += news_vector[index] * self.vector[index]\n",
    "      #   norm = LA.norm(np.nonzero(self.vector))\n",
    "      #   if norm!=0:\n",
    "      #     cosine = cosine / (norm * LA.norm(np.nonzero(news_vector)))\n",
    "      #   else:\n",
    "      #     cosine = NaN\n",
    "      #   self.news_cosines_distances[news]=cosine\n",
    "\n",
    "  def find_cosine_distances_from_related_news(self, all_news):  ############### Why is very slow\n",
    "\n",
    "      self.news_cosines_distances = {}\n",
    "\n",
    "      for news in all_news:\n",
    "        # print(news)\n",
    "        # print(\"SALAMMMMMM\")\n",
    "        news_vector = news.get_vector()\n",
    "        # print(\"news vector \\n {}\".format(news_vector))\n",
    "        self.news_cosines_distances[news] = np.dot(self.vector,news_vector) / (LA.norm(self.vector) * LA.norm(news_vector))\n",
    "\n",
    "      # # with index elimination \n",
    "      # indexes_of_none_zero_terms = np.where(self.vector == 0)[0]\n",
    "      # self.news_cosines_distances = {}\n",
    "     \n",
    "  \n",
    "      # for news in all_news:\n",
    "      #   cosine = 0\n",
    "      #   # print(\"INNN\")\n",
    "      #   news_vector = news.get_vector()\n",
    "      #   for index in indexes_of_none_zero_terms:\n",
    "      #     cosine += news_vector[index] * self.vector[index]\n",
    "      #   norm = LA.norm(np.nonzero(self.vector))\n",
    "      #   if norm!=0:\n",
    "      #     cosine = cosine / (norm * LA.norm(np.nonzero(news_vector)))\n",
    "      #   else:\n",
    "      #     cosine = NaN\n",
    "      #   self.news_cosines_distances[news]=cosine  \n",
    "\n",
    "  def get_top_nearest_news(self, count):\n",
    "    # print(self.title)\n",
    "    top_news = nlargest(count, self.news_cosines_distances, key = self.news_cosines_distances.get)\n",
    "    # print(top_journals.values())\n",
    "    # print(top_journals[0].get_title())\n",
    "    values =[]\n",
    "    urls = []\n",
    "    for news in top_news:\n",
    "      values.append(self.news_cosines_distances[news])\n",
    "      urls.append(news.get_url())\n",
    "\n",
    "    return top_news,values, urls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
